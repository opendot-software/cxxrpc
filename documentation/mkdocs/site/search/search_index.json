{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"C++ Runtime for Parallelism & Concurrency A specification for high performance computing applications enabling implementation to have following traits: High throughput Resposiveness Data Parallel Computation Task Parallelism Potentially Event Based Co-ordination** Pipelining Software Components OS Level Thread Control Library This will be the lowest layer in the entire stack of software Will be used to spawn threads, enable/disable hyperthreading, controll thread to core mapping, potentially control thread local memory allocation using NUMA concepts Abstraction for TCL (Thread Control Library) This will expose user friendly APIs to spawn the threads with custom configurations Thread & Data Management Layer It will store all running threads Will control their eager/lazy execution Will handle the work queue for each thread Will expose APIs to submit work and access state of execution Data Partition Schemes Will allow users to specify the way data is split chunk size, number of chunks Partition Scheduling Schemes How each chunk/partition is mapped to each underlying OS level thread Use Cases Parallel Software Pipeline SPMD & Loop Parallelism Computations Task Parallelism for Network or GUI applications Questions Where does task come into the picture What is the differ or similarity bw partition and chunk Define a standard naming system Will this framework only for for Data Parallel Computational purposes? Can this system be used to expose a user friendly API to define software level pipelines? Can this system be used to for task parallelism e.g., one task/thread runs a logging system, 2nd thread runs the socket recieve logic, 3rd thread runs the transmit logic and 4-8th thread run processing pipeline?","title":"C++ Runtime for Parallelism & Concurrency"},{"location":"#c-runtime-for-parallelism-concurrency","text":"A specification for high performance computing applications enabling implementation to have following traits: High throughput Resposiveness Data Parallel Computation Task Parallelism Potentially Event Based Co-ordination** Pipelining","title":"C++ Runtime for Parallelism &amp; Concurrency"},{"location":"#software-components","text":"","title":"Software Components"},{"location":"#os-level-thread-control-library","text":"This will be the lowest layer in the entire stack of software Will be used to spawn threads, enable/disable hyperthreading, controll thread to core mapping, potentially control thread local memory allocation using NUMA concepts","title":"OS Level Thread Control Library"},{"location":"#abstraction-for-tcl-thread-control-library","text":"This will expose user friendly APIs to spawn the threads with custom configurations","title":"Abstraction for TCL (Thread Control Library)"},{"location":"#thread-data-management-layer","text":"It will store all running threads Will control their eager/lazy execution Will handle the work queue for each thread Will expose APIs to submit work and access state of execution","title":"Thread &amp; Data Management Layer"},{"location":"#data-partition-schemes","text":"Will allow users to specify the way data is split chunk size, number of chunks","title":"Data Partition Schemes"},{"location":"#partition-scheduling-schemes","text":"How each chunk/partition is mapped to each underlying OS level thread","title":"Partition Scheduling Schemes"},{"location":"#use-cases","text":"Parallel Software Pipeline SPMD & Loop Parallelism Computations Task Parallelism for Network or GUI applications","title":"Use Cases"},{"location":"#questions","text":"Where does task come into the picture What is the differ or similarity bw partition and chunk Define a standard naming system Will this framework only for for Data Parallel Computational purposes? Can this system be used to expose a user friendly API to define software level pipelines? Can this system be used to for task parallelism e.g., one task/thread runs a logging system, 2nd thread runs the socket recieve logic, 3rd thread runs the transmit logic and 4-8th thread run processing pipeline?","title":"Questions"}]}